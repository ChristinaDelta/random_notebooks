{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACHINE LEARNING ALGORITHMS PART 3.\n",
    "\n",
    "### Hidden Markov Models (HM models)\n",
    "\n",
    "I will be using information and examples based on the TensorFlow 2.0 course provided by the FreeCodeCamp and the TensorFlow documentation [link](https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel)\n",
    "\n",
    "Import requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HM models are very different from the models used in the previous notebooks. Previously I was using algorithms that rely on data, but HM models deal with probability distributions. Thus, these models deal with probabilities of future events based on past events.\n",
    "\n",
    "Here we'll see how to create and use a HM model to predict the weather. In more detail, we want to predict the weather on any given day, given the probabilty of different events occuring. \n",
    "\n",
    "### Types of Data \n",
    "\n",
    "*What types of data do we use when we work with HM models?* Let's see an example:\n",
    "\n",
    "Let's say we have some specific information about an environment:\n",
    "If it is sunny, we know (hypotheticaly) that there is 80% chance the it is going to be sunny again the next day and 20% chance that it is going to rain.\n",
    "Maybe we also have some information about sunny days and colds days in general.\n",
    "Also, let's say we have some information about the average temperature on these days.\n",
    "\n",
    "Using this information we can create a HM model that will allow us to make predictions for the weather in future given the probability that we discovered. \n",
    "\n",
    "A general definition of what HM models are is as follows:\n",
    "\n",
    "*The Hidden Markov Model is a finite set of states, each of which is associated with a (generally multidimensional) probability distribution. Transitions among the states are governed by a set of probabilities called transition probabilities*. \n",
    "\n",
    "So, in a HM model we have have **a set of states**. In the example above with the information about the weather on a given day, the states would be **hot day** and **cold day**. These states are *hidden* in the model, we never have direct access to these states while we interact with the model.\n",
    "\n",
    "In the model what we look at is something called **observations**. We have a particular outcome/observation at each state.\n",
    "Let's see an example of an observation:\n",
    "*On a hot day Tim has a 80% chance of being happy and a 20% chance of being sad*. This is an observation. At that state (hot day/sunny day) we can **observe** the probability of something happening during that state. \n",
    "\n",
    "So, we don't care about the states in particular but we care about the outcome/observations that we get from that state. \n",
    "\n",
    "#### Data that will be used here\n",
    "\n",
    "In the previous models I used hundreds of datapoints/entries for the modles to train. Here we don't need any of that. What we need here is constant values for transition distributions and observation distributions. \n",
    "\n",
    "**States**: In each markov model we have a finite set of states. These states could be something like \"warm\" and \"cold\" or \"high\" and \"low\" or even \"red\", \"green\" and \"blue\". These states are \"hidden\" within the model, which means we do not direcly observe them.\n",
    "\n",
    "**Observations**: Each state has a particular outcome or observation associated with it based on a probability distribution. An example of this is the following: On a hot day Tim has a 80% chance of being happy and a 20% chance of being sad.\n",
    "\n",
    "**Transitions**: Each state will have a probability defining the likelyhood of transitioning to a different state. An example is the following: a cold day has a 30% chance of being followed by a hot day and a 70% chance of being follwed by another cold day.\n",
    "\n",
    "So, what that means is: there is a probability that we could transition to a different state and for each state we can transition into every other state or a defined set of states given a certain probability.  \n",
    "\n",
    "So, to create a hidden markov model we need:\n",
    "\n",
    "* States\n",
    "* Observation Distribution\n",
    "* Transition Distribution\n",
    "\n",
    "\n",
    "### The Weather model\n",
    "\n",
    "Taken direclty from the TensorFlow documentation [link](https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel).\n",
    "\n",
    "We will model a simple weather system and try to predict the temperature on each day given the following information:\n",
    "* Cold days are encoded by a 0 and hot days are encoded by a 1\n",
    "* The first day in our sequence has an 80% chance of being cold\n",
    "* A cold day has a 30% chance of being followed by a hot day\n",
    "* A hot day has a 20% chance of being followed by a cold day\n",
    "* On each day the temperature is normally distributed with mean and standard deviation 0 and 5 on a cold day and mean and standard deviation 15 and 10 on a hot day\n",
    "* on a hot day the average temperature is 15 and ranges from 5 to 25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's model the above information\n",
    "tfd = tfp.distributions \n",
    "initial_distribution = tfd.Categorical(probs=[0.2, 0.8]) # this refers to point 2 (info 2)\n",
    "transition_distribution = tfd.Categorical(probs=[[0.5, 0.5], [0.2, 0.8]]) # this refers to point 3 and 4\n",
    "observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.]) # this goes to point 5 \n",
    "\n",
    "# the loc argument represents the mean and the scale is the standard devitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now created distribution variables to model our system and it's time to create the hidden markov model:\n",
    "The arguments/parameters that the model needs are:\n",
    "* initial distribution\n",
    "* transition distribution\n",
    "* obserrvation distribution\n",
    "* number of steps\n",
    "\n",
    "#### What is the number of steps?\n",
    "\n",
    "the num of steps is *how many days we want the model to predict* the expected weather/temperature.\n",
    "\n",
    "The number of times we are going to **step** on this model and run the cicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfd.HiddenMarkovModel(\n",
    "    initial_distribution=initial_distribution,\n",
    "    transition_distribution=transition_distribution,\n",
    "    observation_distribution=observation_distribution,\n",
    "    num_steps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.HiddenMarkovModel(\"HiddenMarkovModel\", batch_shape=[], event_shape=[7], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the **expected temperatures** on each day we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.       11.1      10.83     10.748999 10.724699 10.71741  10.715222]\n"
     ]
    }
   ],
   "source": [
    "mean = model.mean() # this is called \"partially defined tensor\"\n",
    "\n",
    "# due to the way TensorFlow works on a lower level we need to evaluate part of the graph from within a session \n",
    "# to see the value of this tensor\n",
    "\n",
    "# in the new version of tensorflow we need to use tf.compat.v1.Session() rather than just tf.Session()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
