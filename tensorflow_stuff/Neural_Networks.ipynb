{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURAL NETWORKS WITH TENSORFLOW\n",
    "\n",
    "I will be using information and examples based on the TensorFlow 2.0 course provided by the FreeCodeCamp and the TensorFlow documentation [link](https://www.tensorflow.org/tutorials/keras/classification).\n",
    "\n",
    "In this notebook I will provide information on how to create and use a neural network to classify articles of clothing. To achieve this, I will use a sub module of TensorFlow called **keras**.\n",
    "\n",
    "**What is Keras?**\n",
    "\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation.\n",
    "\n",
    "Use Keras if you need a deep learning library that:\n",
    "* Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility)\n",
    "* Supports both convolutional networks and recurrent networks, as well as combinations of the two\n",
    "* Runs seamlessly on CPU and GPU\n",
    "\n",
    "With keras we don't have to build neural networks from scratch. It hides a lot of mathematical complexity (that otherwise we would have to implement) inside of helpful packages, modules and methods, thus, making it very easy to work with neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some theoritical information before diving into creating a Neural Network:\n",
    "\n",
    "* What is a Neural Network?\n",
    "* How does a Neural Network work?\n",
    "* What is the math involved in Neural Networks?\n",
    "* What is back propagetion?\n",
    "* What is gradient descent?\n",
    "* How information actually flows through the network?\n",
    "\n",
    "Neural Networks are complex. There are a lot of components that go into them. Here, I will try to write as much theoretical information as possible and explain things part by part before combining everything in the end.\n",
    "\n",
    "### What are Neural Networks and how do they work\n",
    "\n",
    "##### what's a neural network?\n",
    "\n",
    "Let's start simple. The whole point of a neural network is to provide classification or predictions.\n",
    "We have some input information, we feed that information to the neural network and then we want it to give us some output. As previously mentioned a neural network is a layered representation of data(information), and normally in neural networks we have **multiple layers**. In the core machine learning algorithms (like linear regression) data was not transformed or modified within the model, it simply existed in one layer. We passed some features to our model, some math was done, an answer (label) was returned. The data was not changed or transformed throughout this process.\n",
    "\n",
    "A neural network processes our data differently. It attempts to represent our data in different ways and in different dimensions by applying specific operations to transform our data at each layer. Another way to express this is that at each layer our data is transformed in order to learn more about it. By performing these transformations, the model can better understand our data and therefore provide a better **prediction**.\n",
    "\n",
    "##### what's a neural network made of?\n",
    "\n",
    "The architecture of a Neural Network is as follows:\n",
    "\n",
    "* Input layer\n",
    "* Hidden Layer(s)\n",
    "* Output Layer\n",
    "* Neurons(nodes)\n",
    "* Connected Layers \n",
    "\n",
    "![Imgur](https://i.imgur.com/3NO9kj6.png) \n",
    "\n",
    "As we mentioned earlier each neural network consists of multiple layers. At each layer a different transformation of data occurs. Our initial input data is fed through the layers and eventually arrives at the output layer where we will obtain the result.\n",
    "\n",
    "**Input layer**\n",
    "\n",
    "The input layer is the layer that our initial (raw) data is passed to. It is the first layer in our neural network. \n",
    "\n",
    "**Hidden Layer(s)**\n",
    "\n",
    "Hidden Layers exist between the Input Layer and the Output Layer. The reason they are called *hidden* is because they are hidden to us, we cannot observe them. Most neural networks consist of at least one hidden layer but can have an unlimited amount. Typically, the more complex the model the more hidden layers.\n",
    "\n",
    "**Output Layer**\n",
    "\n",
    "The output layer is the layer that we will retrive our results from. Once the data has passed through all other layers it will arrive here.\n",
    "\n",
    "**Neurons**\n",
    "\n",
    "Each layer is made up of neurons. Neurons are responsible for generating/holding/passing ONE numeric value.\n",
    "For example, our input layer will have as many neurons as we have input information. Let's say we want to pass an image that is of 3x3 pixels, thats 9 pixels. This means that we would need 9 neurons in our input layer to hold each of these pixels.\n",
    "\n",
    "This also means that our output layer will have as many neurons as we have output information. The output is a little bit more complicated to understand and will be discussed later.\n",
    "\n",
    "But what about our **hidden layers**? Well these can have as many neurons as we decide. We'll discuss how we can pick these values later but understand a hidden layer can have any number of neurons.\n",
    "\n",
    "**Connected Layers**\n",
    "\n",
    "So how are all these layers connected? Well the neurons in one layer will be connected to neurons in the subsequent layer. However, the neurons can be connected in a variety of different ways.\n",
    "Take for example the figure above. Each neuron in one layer is connected to every neuron in the next layer. This is called a **dense layer**. There are many other ways of connecting layers but well discuss those as we see them.\n",
    "\n",
    "### Weights and Biases\n",
    "\n",
    "#### Weights\n",
    "\n",
    "Weights are associated with each connection in our neural network. Every pair of connected nodes will have one weight that denotes the strength of the connection between them. These are vital to the inner workings of a neural network and will be tweaked as the neural network is trained. The model will try to determine what these weights should be to achieve the best result. Weights start out at a constant or random value and will change as the network sees training data.\n",
    "\n",
    "#### Biases\n",
    "\n",
    "Biases are another important part of neural networks and will also be tweaked as the model is trained. A bias is simply a constant value associated with each layer. It can be thought of as an extra neuron that has no connections. The purpose of a bias is to shift an entire **activation function** by a constant value. This allows a lot more flexibllity when it comes to choosing an activation and training the network. There is one bias for each layer.\n",
    "\n",
    "I'll discuss **activation functions** in more detail later.\n",
    "\n",
    "### Types of Data\n",
    "\n",
    "The type of data a neural network processes varies drastically based on the problem being solved. When we build a neural network, we define what shape and kind of data it can accept. It may sometimes be neccessary to modify our dataset so that it can be passed to our neural network.\n",
    "\n",
    "Some common types of data a neural network uses are the following:\n",
    "\n",
    "* Vector Data (2D)\n",
    "* Timeseries or Sequence (3D)\n",
    "* Image Data (4D)\n",
    "* Video Data (5D)\n",
    "\n",
    "There are of course many different types or data, but these are the main categories.\n",
    "\n",
    "### A few things about the math involved in Neural Networks\n",
    "\n",
    "On a lower level neural networks are simply a combination of elementry math operations and some more advanced linear algebra. Each neural network consists of a sequence of layers in which data passes through. These layers are made up on neurons and the neurons of one layer are connected to the next (as previously mentioned). These connections are defined by a weight (some numeric value). Each layer also has a bias, this is simply an extra neuron that has no connections and holds a single numeric value. Data starts at the input layer and is trasnformed as it passes through subsequent layers. The data at each subsequent neuron is defined as the following:\n",
    "\n",
    "$Y =(\\sum_{i=0}^n w_i x_i) + b$\n",
    "\n",
    "where,\n",
    "\n",
    "$w$ stands for the weight of each connection to the neuron\n",
    "\n",
    "$x$ stands for the value of the connected neuron from the previous value\n",
    "\n",
    "$b$ stands for the bias at each layer (this is a constant)\n",
    "\n",
    "$n$ is the number of connections\n",
    "\n",
    "$Y$ is the output of the current neuron\n",
    "\n",
    "$\\sum$ stands for sum\n",
    "\n",
    "The equation above is called a weighed sum. We will take this weighted sum at each and every neuron as we pass information through the network. Then we will add what's called a bias to this sum. The bias allows us to shift the network up or down by a constant value. It is like the y-intercept of a line.\n",
    "\n",
    "#### Activation Function\n",
    "\n",
    "The above equation is the not a complete one! We forgot a crucial part, the **activation function**. This is a function that we apply to the equation seen above to add complexity and dimensionality to our network. Our new equation with the addition of an activation function $F(x)$ is seen below:\n",
    "\n",
    "$Y =F((\\sum_{i=0}^n w_i x_i) + b)$\n",
    "\n",
    "Our network will start with predefined activation functions (they may be different at each layer) but the weights and biases are random. As we train the network by feeding it data it will learn the correct weights and biases and adjust the network accordingly using a technqiue called **backpropagation** (explained later). Once the correct weights and biases have been learned our network will hopefully be able to give us meaningful predictions. We get these predictions by observing the values at our final layer, the output layer. Take a look at the image/figure below:\n",
    "\n",
    "![Imgur](https://i.imgur.com/14R7Kmp.png)\n",
    "\n",
    "Activation functions reside within neurons, but not all neurons (as seen in the figure 2 above). Hidden and output layer neurons use activation functions, but input layer neurons do not.\n",
    "Activation functions perform a transformation on the input received, in order to keep values within a manageable range. Since values in the input layers are generally centered around zero and have already been appropriately scaled, they do not require transformation. However, these values, once multiplied by weights, summed (and once we add the bias at the end as in the equation above) quickly get beyond the range of their original scale, which is where the activation functions come into play, forcing values back within this acceptable range and making them useful.\n",
    "\n",
    "In order to be useful, activation functions must also be **nonlinear** and **continuously differentiable**. Nonlinearity allows the neural network to be a universal approximation; a continuously differentiable function is necessary for gradient-based optimization methods, which is what allows the efficient back propagation of errors throughout the network and will be discussed in detail below. \n",
    "\n",
    "Inside the neuron:\n",
    "\n",
    "* an activation function is assigned to the neuron or entire layer of neurons\n",
    "* weighted sum of input values are added up\n",
    "* the activation function is applied to weighted sum of input values and transformation takes place\n",
    "* the output to the next layer consists of this transformed value\n",
    "\n",
    "#### Types of Activation Functions\n",
    "\n",
    "Theoretically any number of functions could be used as activation functions, as long as they meet the above requirements. However, a small number of functions are most relied upon. Let's see these functions as well as their shapes:\n",
    "\n",
    "![Imgur](https://i.imgur.com/J2gHgts.png)\n",
    "\n",
    "**Sigmoid**\n",
    "\n",
    "The sigmoid function \"squashes\" values to the range 0 and 1 and it is mainly used for binary classification in the output layer.\n",
    "\n",
    "**Tanh**\n",
    "\n",
    "The tanh function \"squashes\" values to the range -1 and 1. The output values are, therefore, centered around zero and it can be thought of as a scaled, or shifted, sigmoid. This is why it is almost always preferable to the sigmoid function.\n",
    "\n",
    "**Rectified Linear Unit (ReLU)**\n",
    "\n",
    "This activation function takes the form of $f(x) = max(0, x)$. Transformation leads positive values to be 1, and negative values to be zero. It is considered to accelerate convergence of gradient descent compared to above functions and it has become the default activation function for hidden layers.\n",
    "\n",
    "### What is Backpropagation? \n",
    "\n",
    "Backpropagation is the fundemental algorithm behind training neural networks. It is what changes the weights and biases of our network. To fully explain this process, we need to discuss and understand something called a **cost/loss function**.\n",
    "\n",
    "#### cost/loss function\n",
    "\n",
    "So far we know that a neural network holds, transforms and passes information through the layers until it eventually reaches an output layer. The output layer contains the results that we look at to determine the prediciton from our network. In the training phase it is likely that our network will make many mistakes and poor predicitions. In fact, at the beginning of training, our network doesn't know anything (remeber, it has random weights and biases)!\n",
    "\n",
    "We need some way of evaluating if the network is doing well and how well it is doing. For our training data we have the features (input) and the labels (expected output). This way we can compare the output from our network to the expected output. Based on the difference between these values we can determine if our network has done a good job or a bad job. If the network has done a good job, we'll make minor changes to the weights and biases. If it has done a bad job, our changes may be more drastic.\n",
    "\n",
    "So, this is where the **cost/loss function** comes in. This function is responsible for determining how well the network did. We pass it the network's output and the expected output, and it returns to us some value representing the cost/loss of the network. This effectively makes the network's job to optimize this cost function, trying to make it as low as possible (the lower the value that this function gives us the better).\n",
    "\n",
    "Here is a list of a few common loss/cost functions:\n",
    "\n",
    "* Mean Squared Error\n",
    "* Mean Absolute Error\n",
    "* Hinge Loss\n",
    "\n",
    "#### Gradient Descent\n",
    "\n",
    "Gradient descent and backpropagation are closely related. Gradient descent is the algorithm used to find the optimal paramaters (weights and biases) for our network, while backpropagation is the process of calculating the gradient that is used in the gradient descent step.\n",
    "\n",
    "Gradient descent requires some pretty advanced calculus and linear algebra to understand so I will stay away from that for now. Let's see the formal definition:\n",
    "*Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.*\n",
    "\n",
    "#### Optimizer\n",
    "\n",
    "We may sometimes see the term optimizer or optimization function. This is simply the function that implements the backpropagation algorithm described above. Here's a list of a few common ones:\n",
    "\n",
    "* Gradient Descent\n",
    "* Stochastic Gradient Descent\n",
    "* Mini-Batch Gradient Descent\n",
    "* Momentum\n",
    "* Nesterov Accelerated Gradient\n",
    "\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "*I will be passing more information and changing things while I learn, so this notebook alongside with all the other notebooks in the tensorflow directory will be continuously updated*. \n",
    "\n",
    "## Let's build and train a basic neural network\n",
    "\n",
    "For more info about coding a NN see [link](https://www.tensorflow.org/tutorials/keras/classification). This is where I got the dataset and coding information from.\n",
    "\n",
    "### Dataset that will be used here\n",
    "\n",
    "I will use the MNIST Fashion Dataset. This is a dataset that is included in keras, it includes 60,000 images for training and 10,000 images for validation/testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "# split data into training and testing\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data to see what we are goingto work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, in train_images we have 60000 images of 28x28 pixels (this will be 784 input neurons for each image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at 1 pixel:\n",
    "train_images[0,23,23] # 1st image, row 23, column 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains grayscale images only (no colour channels). Now, the values at each pixel are between 0 and 255 where 0 is black and 255 is white, the pixel we chose is close to white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have a look at the first few training labels:\n",
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, what are our labels made of?**\n",
    "\n",
    "We have an array of integers between 0 and 9. What do these numbers represent?\n",
    "\n",
    "They represent a specific piece of clothing. Let's create an array of label names to indicate each one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "              'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at what some of these images look like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0]) # let's look at the 2nd image of our training dataset\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing \n",
    "\n",
    "The last step before creating the model is to **preprocess** our data. This simply means applying some prior transformations to our data before passing them to the model. \n",
    "\n",
    "Here, I will simply scale all our greyscale pixel values (0-255) to be between 0 and 1. This can be done by dividing each value in the training and testing sets by 255.0. \n",
    "\n",
    "*Why would we want our input data to be between 0 and 1?*\n",
    "\n",
    "Typically, it is a good idea to have your input data in between that range. The reason is because when the neural network starts the tarining process, the (random) values of the trainable parameters w and b are in that range. If we pass large input values (0-255 for example) and tiny weights and biases it will be dificult for the network to classify that information because it will need to work harder to update those weights and biases to reduce how large those values are going to be. \n",
    "\n",
    "So, the smaller the values we pass to the Network, the easier it is for the Network to process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0 # make sure that your testing data comes in the same form as your training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14901960784313725"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the new values\n",
    "train_images[34, 13, 13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Network\n",
    "\n",
    "Now it's time to build the model, woohoo! \n",
    "I am going to use a **keras sequential** model with three different layers. This model represents a feed-forward neural network (which means that it passes values from left to right). \n",
    "\n",
    "I'll break down each layer and its architecture later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x108f61f90>\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28, 28)),  # input layer (1)\n",
    "    keras.layers.Dense(128, activation = 'relu'),  # hidden layer (2)\n",
    "    keras.layers.Dense(10, activation = 'softmax') # output layer (3)                   \n",
    "])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's break down the above code. \n",
    "\n",
    "Here I am using the **Sequential method** of keras, which is the most basic form of neural networks. The information here flows sequentially, passing from left to the right (note, in other notebooks I will also play around with recurent and convolutional neural networks). For more information about this method see [link](https://keras.io/models/sequential/). \n",
    "\n",
    "After defining the method, we need to define the layers of the model:\n",
    "* 1st layer: This is the input layer. *What does **flatten** mean here?*\n",
    "\n",
    "Well, **flatten** allows us to take the input shape (which is defined as 28x28 pixels) and flatten all the pixels into 784. This will result in a single value per input neuron.\n",
    "\n",
    "* 2nd layer: This is our (first) hidden layer and it is a **dense** layer. This mean that every neuron of that layer will be connected to all the neurons of the previous layer (the input layer). \n",
    "\n",
    "This layer consists of 128 neurons. *Why*? I have no idea. This code was taken directly from the tensorflow documentation and they don't axplain why they came up with that number. Anyhow, normally we would not want our hidden layer to have **much** larger number of neurons than the input layer (I think!).\n",
    "\n",
    "Lastly, we chose the **ReLU** activation function, which gives values of zero when tehry are negative and values of 1 when they positive. Remember, this functions is prefered in the hidden layers.\n",
    "\n",
    "* 3rd layer: This is our output layer, which is also dense. \n",
    "\n",
    "This layer has 10 neurons. *Why?*\n",
    "Well, our label consists of 10 values representing 10 different types of clothing (can also be called classes). So, the output layer has the predictions of the type of clothing for each image by giving a value (between 0 and 1) for each of the types/classes. **Remember the probability distribution?**\n",
    "\n",
    "Lastly, the activation function chosen here is **softmax**. The reason is because we are going to have a probability distribution for our 10 classes. Softmax is the function that makes sure all the values in the output neurons add up to 1 and that they are between 0 and 1. For more information about this function check [link](https://www.machinecurve.com/index.php/2020/01/08/how-does-the-softmax-activation-function-work/) \n",
    "\n",
    "### Compile the Model\n",
    "\n",
    "Now that the model is almost ready, we have built the architecture of the model and now, we just need to compile it. This means that we need define the loss function, optimizer and metrics we would like to track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we did above. \n",
    "\n",
    "* Optimizer: The algorithm we are using is the **adam** which performs gradient descent (see information in the beginning). \n",
    "\n",
    "* loss: Here we use the **sparse_categorical_crossentropy**. *Why?*\n",
    "\n",
    "Because our **targets** are in categorical format. We have 10 classes, the target-class for each sample is in a 10-dimensional vector that is all-zeros except for a 1 at the index corresponding to the class of the sample. \n",
    "\n",
    "* metrics: this is the output that we want to see (which is **accuracy** in our case). \n",
    "\n",
    "### Training the Model\n",
    "\n",
    "Now it is time to finally train the model. Since we've already done all the work on our data this step is as easy as calling a single method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4995 - accuracy: 0.8238\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3762 - accuracy: 0.8647\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3375 - accuracy: 0.8778\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3150 - accuracy: 0.8852\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2971 - accuracy: 0.8903\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2824 - accuracy: 0.8945\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2711 - accuracy: 0.8991\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2593 - accuracy: 0.9032\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2507 - accuracy: 0.9063\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2412 - accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x129b50890>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now just pass the training data, labels and epochs and wait for the magic to happen!\n",
    "model.fit(train_images, train_labels, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with the accuracy..\n",
    "We se that during the last epoch our accuracy is 91% but, this is the accuracy on our **training data**. If we want to find out what our true accuracy is, we need to evaluate the model on our testing data.\n",
    "\n",
    "### Evaluating the Model\n",
    "\n",
    "Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=1) \n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does **verbose** mean?\n",
    "It is simply the amount of information that we are seeing as the model evaluates.. or how much information is printed at the console.\n",
    "Here we see the loss and test accuracy. \n",
    "\n",
    "Now, we see that the test accuracy is less than the training accuracy. \n",
    "\n",
    "This is an example of something called **overfitting**. \n",
    "\n",
    "Our model seemed to do pretty well on the training data but that is because it would see that data often (10 times in our case). Once we passed new data that it had not seen before its accuracy droped to 88%. This means that we quite overfit our model and it is not good at generalizing for other datasets which is usually the goal. \n",
    "\n",
    "When we create a new model we want the highest possible accuracy when training but we also want consistency in the accuracy when evaluating the model with new datasets. We need to make sure that the model generilizes properly. \n",
    "\n",
    "### Making predictions with our Model\n",
    "\n",
    "Making predictions is very easy. We are going to use the ```.predict()``` method adn we will just pass an array of data **in the form** we've specified in the input layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method returns to us an array of predictions for each image we passed it. Let's have a look at the predictions for image 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.1212631e-06, 1.9841859e-09, 1.5529619e-09, 7.3351047e-12,\n",
       "       3.3427096e-07, 2.1180979e-03, 8.9291859e-08, 4.1311856e-02,\n",
       "       4.1508002e-07, 9.5656300e-01], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the fact that we have 10 values in the array. *Why is that?*\n",
    "\n",
    "Well, we have 10 classes, 10 output neurons and, we wanted our model to give us a *prediction value* for each class. So the output here (this array) is the probability distribution that we have calculated for this image (1st image). \n",
    "\n",
    "Now, these values are really tiny. If we want to look at the largest of the values (let's keep on looking at this same image) we would need to specify it using a numpy function calle ```argmax()```. This will return us the **index** of the maximum value for this array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the value for the last class (which is ankle boot) has the highst probability, and if we go back to the part where I plot the images, we'll see that the 1st image was indeed an ankle boot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(test_images[0]) # let's look at the 1nd image of our testing dataset\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle boot\n"
     ]
    }
   ],
   "source": [
    "# to see if the class is indeed ankle boot:\n",
    "print(class_names[np.argmax(predictions[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test any of the predictions with the testing images by changing the values in ```print(class_names[np.argmax(predictions[])])``` and in ```plt.imshow(test_images[0])```\n",
    "\n",
    "### Playing around with the model and making predictions\n",
    "\n",
    "Below is a script that I stole from the TesnorFlow 2.0 course. This script uses our model to make predictions on any entry/image that we want. The user just needs to type a number (0-999), the script will find the image that corresponds to that number in the **test dataset**, it will make a prediction from the model that we created and it will show us what that image actually was vs what it was predicted to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick a number: 10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "COLOR = 'white'\n",
    "plt.rcParams['text.color'] = COLOR\n",
    "plt.rcParams['axes.labelcolor'] = COLOR\n",
    "\n",
    "def predict(model, image, correct_label):\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    prediction = model.predict(np.array([image]))\n",
    "    predicted_class = class_names[np.argmax(prediction)]\n",
    "    \n",
    "    show_image(image, class_names[correct_label], predicted_class)\n",
    "\n",
    "\n",
    "def show_image(img, label, guess):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    plt.title(\"Excpected: \" + label)\n",
    "    plt.xlabel(\"Guess: \" + guess)\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_number():\n",
    "    \n",
    "    while True:\n",
    "        num = input(\"Pick a number: \")\n",
    "        if num.isdigit():\n",
    "            num = int(num)\n",
    "            if 0 <= num <= 1000:\n",
    "                return int(num)\n",
    "            else:\n",
    "                print(\"Try again...\")\n",
    "    \n",
    "num = get_number()\n",
    "image = test_images[num]\n",
    "label = test_labels[num]\n",
    "predict(model, image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
