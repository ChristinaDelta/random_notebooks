{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACHINE LEARNING ALGORITHMS PART 2.\n",
    "\n",
    "### Classification\n",
    "\n",
    "I will be using information and examples based on the **TensorFlow 2.0** course provided by the FreeCodeCamp and the TensorFlow documentation [doc](https://www.tensorflow.org/tutorials/estimator/premade).\n",
    "\n",
    "First, let's import the requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow_core._api.v2.version' from '/Users/christinadelta/environments/tensorflowTut_env/lib/python3.7/site-packages/tensorflow_core/_api/v2/version/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is classification?\n",
    "\n",
    "Classification is differentiating between data points and seperating them into classes. \n",
    "Rather than predicting a numeric value (y labels) as in Regression, in Classification we predict classes.\n",
    "We predict the probability that one specific datapoint/entry is within all the different classes it could be.\n",
    "\n",
    "Here, we'll see how to solve a classification problem in TensorFlow using **Estimators**.  \n",
    "\n",
    "### Loading the Data\n",
    "\n",
    "The dataset that I will use here comes from the TensorFlow website. \n",
    "\n",
    "The dataset seperates Iris flowers in three different species (which will be our labels/y values):\n",
    "* Setosa \n",
    "* Versicolor\n",
    "* Virginica\n",
    "\n",
    "And four information about each flower (which will be the features/x values):\n",
    "* Sepal length\n",
    "* Sepal width\n",
    "* Petal length\n",
    "* Petal width\n",
    "\n",
    "Based on the information above, let's define a few helpful constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species'] # headers of features\n",
    "SPECIES_COLUMN_NAMES = ['Setosa', 'Versicolor', 'Virginica'] # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Iris datasets using Keras. We need to download two seperate datasets.\n",
    "# One for training and one for testing\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the datasets using Pandas\n",
    "train_df = pd.read_csv(train_path, names = FEATURE_COLUMN_NAMES, header = 0)\n",
    "test_df = pd.read_csv(test_path, names = FEATURE_COLUMN_NAMES, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0           6.4         2.8          5.6         2.2        2\n",
       "1           5.0         2.3          3.3         1.0        1\n",
       "2           4.9         2.5          4.5         1.7        2\n",
       "3           4.9         3.1          1.5         0.1        0\n",
       "4           5.7         3.8          1.7         0.3        0\n",
       "5           4.4         3.2          1.3         0.2        0\n",
       "6           5.4         3.4          1.5         0.4        0\n",
       "7           6.9         3.1          5.1         2.3        2\n",
       "8           6.7         3.1          4.4         1.4        1\n",
       "9           5.1         3.7          1.5         0.4        0\n",
       "10          5.2         2.7          3.9         1.4        1\n",
       "11          6.9         3.1          4.9         1.5        1\n",
       "12          5.8         4.0          1.2         0.2        0\n",
       "13          5.4         3.9          1.7         0.4        0\n",
       "14          7.7         3.8          6.7         2.2        2\n",
       "15          6.3         3.3          4.7         1.6        1\n",
       "16          6.8         3.2          5.9         2.3        2\n",
       "17          7.6         3.0          6.6         2.1        2\n",
       "18          6.4         3.2          5.3         2.3        2\n",
       "19          5.7         4.4          1.5         0.4        0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect a few things in the datasets\n",
    "# train_df.head(10)\n",
    "train_df.shape\n",
    "test_df.shape\n",
    "#test_df.head(20)\n",
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_df has 120 values for each feature/label and the test_df has only 30. It's a pretty small dataset.\n",
    "When running ```train_df.head()``` we notice that **species** are defined numericaly (0, 1, 2). These numerical representations of Species are:\n",
    "* Setosa = 0\n",
    "* Versicolor = 1\n",
    "* Virginica = 2\n",
    "\n",
    "The values of the rest of the information (our features) are defined in cm. \n",
    "\n",
    "Now let's extract the labels from the datasets using the ```dataframe.pop()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0            6.4         2.8          5.6         2.2\n",
      "1            5.0         2.3          3.3         1.0\n",
      "2            4.9         2.5          4.5         1.7\n",
      "3            4.9         3.1          1.5         0.1\n",
      "4            5.7         3.8          1.7         0.3\n",
      "..           ...         ...          ...         ...\n",
      "115          5.5         2.6          4.4         1.2\n",
      "116          5.7         3.0          4.2         1.2\n",
      "117          4.4         2.9          1.4         0.2\n",
      "118          4.8         3.0          1.4         0.1\n",
      "119          5.5         2.4          3.7         1.0\n",
      "\n",
      "[120 rows x 4 columns]\n",
      "0      2\n",
      "1      1\n",
      "2      2\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "115    1\n",
      "116    1\n",
      "117    0\n",
      "118    0\n",
      "119    1\n",
      "Name: Species, Length: 120, dtype: int64\n"
     ]
    }
   ],
   "source": [
    " train_y = train_df.pop('Species')\n",
    "test_y = test_df.pop('Species')\n",
    "\n",
    "# check that the Species column is gone\n",
    "print(train_df)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming with Estimators \n",
    "\n",
    "Once the dataframe is set up, we define our model using a TensorFlow Estimator. An **Estimator** is a class (any class) derived from ```tf.estimator.Estimator()```. TensrorFlow provides a collection of ```tf.estimator``` such as: ```LinearRegessor``` to implement ML algorithms. We can write our own Estimators but, TensorFlow suggests that beginners use the pre-made Estimators. So, to use pre-made Estimators of TensorFlow we need to first perform a few tasks:\n",
    "* Create an input function\n",
    "* Define the model's feature columns\n",
    "* Instantiate an Estimator, specifying the feature columns and other parameters\n",
    "* Call one or more methods on the Estimator object, passing the appropriate input function as the source of the data\n",
    "\n",
    "For more information about pre-made Estimators look at the TensorFlow Documentation [link](https://www.tensorflow.org/tutorials/estimator/premade).\n",
    "\n",
    "### Create an Input function\n",
    "\n",
    "So the **input function** creates a ```tf.data.Dataset``` object in which the outputs are two element tuples. These tuples contain:\n",
    "\n",
    "* **Features** in the form of dictionaries (with a key and a value):\n",
    "    * Each key is the name of the feature\n",
    "    * Each value is an array with that feature's values\n",
    "    \n",
    "* **Label** which is an array with the values of the labels\n",
    "\n",
    "Here is the format of such an input function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_evaluation_func():\n",
    "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
    "               'SepalWidth': np.array([2.8, 2.3]),\n",
    "               'PetalLength': np.array([5.6, 3.8]),\n",
    "               'PetalWidth': np.array([2.2, 1.0])}\n",
    "    labels = np.array([2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input function may generate the features and labels any way we like. The above function will not be used, it was was created just to get an idea of the object dataset with the two-element tuples.\n",
    "\n",
    "Now, let's create an input function the way it was done in Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training = True, batch_size = 256):\n",
    "    # convert the inputs to a Dataset object \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    \n",
    "    # shuffle and repeat if you are training the model\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "        \n",
    "    return(dataset.batch(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the feature columns\n",
    "\n",
    "A **feature column** is an object (a list) that describes how the model should use the input data from the features dictionary (the dataset object). So when we build an Estimator model, we pass it a list of feature columns that describe each of the features that we want our model to use. To do that we use the ```tf.feature_column``` module in a similar way that it was done in regression. Only here we don't have to convert any categorical values to numeric so it's mucch easier. \n",
    "\n",
    "For this dataset I'll make a list of feature columns to tell the model to represent each of the features as 32-bit floating points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns tell the model how to use an input:\n",
    "my_feature_columns = []\n",
    "for key in train_df.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key = key))\n",
    "    \n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the description of how we want the model to represent our features we can build the model.\n",
    "\n",
    "### Building the Model\n",
    "\n",
    "So with this dataset we have a classic Classification task and a few main choices that we can use:\n",
    "* ```.DNNClassifier``` for deep models that perform multi-class classification\n",
    "* ```.LinearClassifier``` based on linear models. A linear classifier works similarly to linear regression except, it does classification rather than regression, so we get the probability of being a specific label rathen than a numeric value. \n",
    "\n",
    "For this classification task ```tf.estimator.DNNClassifier``` seems like an appropriate option and this is because we may not be able to find a linear coorespondence in our data with the ```.LinearClassifier```. \n",
    "\n",
    "Here is how we can use this model (Estimator):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/04/l_r6_2qd69907ztc_b_d2qz00000gn/T/tmp7gmac15_\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/04/l_r6_2qd69907ztc_b_d2qz00000gn/T/tmp7gmac15_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# build a DNN with 2 hidden layers with 30  and 10 hidden nodes each\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns = my_feature_columns, hidden_units = [30, 10], n_classes = 3) # 2 hidden layers of 30 and 10 \n",
    "#nodes respectively and three classes for the model to choose from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the code. The ```tf.estimator``` is a module with a bunch of stored pre-made models(Estimators) and the DNNClassifier is one of them. \n",
    "For this model what we need to pass is:\n",
    "* our feature_columns list (created earlier)\n",
    "* number of hidden layers\n",
    "* number of classes\n",
    "\n",
    "#### Hidden Layers \n",
    "\n",
    "Hidden layers is like building the architecture of the neural network. We have an input layer, hidden layers and an output layer. Neural Networks will be discussed later on. \n",
    "\n",
    "#### Classes\n",
    "\n",
    "We predefined the number of classes in the beginning. This dataset has a label with 3 kinds of information (setosa, versicolor, virginica). These are our classes.\n",
    "\n",
    "## Training, evaluating, predicting \n",
    "\n",
    "Now that our model is ready we can call methods to train it , evaluate it and to make predictions. \n",
    "\n",
    "### Train the model\n",
    "\n",
    "we can train our model by calling the ```.train``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/christinadelta/environments/tensorflowTut_env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/christinadelta/environments/tensorflowTut_env/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christinadelta/environments/tensorflowTut_env/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/adagrad.py:103: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/04/l_r6_2qd69907ztc_b_d2qz00000gn/T/tmp7gmac15_/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.3951308, step = 0\n",
      "INFO:tensorflow:global_step/sec: 313.81\n",
      "INFO:tensorflow:loss = 0.9323428, step = 100 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.334\n",
      "INFO:tensorflow:loss = 0.84580696, step = 200 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.755\n",
      "INFO:tensorflow:loss = 0.77220345, step = 300 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.299\n",
      "INFO:tensorflow:loss = 0.7329195, step = 400 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.175\n",
      "INFO:tensorflow:loss = 0.69301426, step = 500 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.668\n",
      "INFO:tensorflow:loss = 0.66526455, step = 600 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.87\n",
      "INFO:tensorflow:loss = 0.6412647, step = 700 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.679\n",
      "INFO:tensorflow:loss = 0.6147226, step = 800 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.229\n",
      "INFO:tensorflow:loss = 0.5974794, step = 900 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.585\n",
      "INFO:tensorflow:loss = 0.57966506, step = 1000 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.487\n",
      "INFO:tensorflow:loss = 0.56572664, step = 1100 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.78\n",
      "INFO:tensorflow:loss = 0.548915, step = 1200 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.955\n",
      "INFO:tensorflow:loss = 0.5289853, step = 1300 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.002\n",
      "INFO:tensorflow:loss = 0.51512665, step = 1400 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.593\n",
      "INFO:tensorflow:loss = 0.50890714, step = 1500 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.083\n",
      "INFO:tensorflow:loss = 0.4953031, step = 1600 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.531\n",
      "INFO:tensorflow:loss = 0.50116736, step = 1700 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.413\n",
      "INFO:tensorflow:loss = 0.487371, step = 1800 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.529\n",
      "INFO:tensorflow:loss = 0.47582334, step = 1900 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.406\n",
      "INFO:tensorflow:loss = 0.4642306, step = 2000 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.125\n",
      "INFO:tensorflow:loss = 0.45702136, step = 2100 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.498\n",
      "INFO:tensorflow:loss = 0.46137887, step = 2200 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.597\n",
      "INFO:tensorflow:loss = 0.44623268, step = 2300 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.738\n",
      "INFO:tensorflow:loss = 0.4318381, step = 2400 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.29\n",
      "INFO:tensorflow:loss = 0.43617648, step = 2500 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.372\n",
      "INFO:tensorflow:loss = 0.41428173, step = 2600 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.044\n",
      "INFO:tensorflow:loss = 0.41874355, step = 2700 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.487\n",
      "INFO:tensorflow:loss = 0.40776113, step = 2800 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.119\n",
      "INFO:tensorflow:loss = 0.41347802, step = 2900 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.613\n",
      "INFO:tensorflow:loss = 0.40679657, step = 3000 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.777\n",
      "INFO:tensorflow:loss = 0.40006793, step = 3100 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.908\n",
      "INFO:tensorflow:loss = 0.3810368, step = 3200 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.053\n",
      "INFO:tensorflow:loss = 0.38560724, step = 3300 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.647\n",
      "INFO:tensorflow:loss = 0.3739997, step = 3400 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.727\n",
      "INFO:tensorflow:loss = 0.379982, step = 3500 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.04\n",
      "INFO:tensorflow:loss = 0.3764032, step = 3600 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.19\n",
      "INFO:tensorflow:loss = 0.35173696, step = 3700 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.095\n",
      "INFO:tensorflow:loss = 0.36686075, step = 3800 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.566\n",
      "INFO:tensorflow:loss = 0.36323684, step = 3900 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.357\n",
      "INFO:tensorflow:loss = 0.3409137, step = 4000 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.648\n",
      "INFO:tensorflow:loss = 0.35312223, step = 4100 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.257\n",
      "INFO:tensorflow:loss = 0.3480584, step = 4200 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.698\n",
      "INFO:tensorflow:loss = 0.34959668, step = 4300 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.846\n",
      "INFO:tensorflow:loss = 0.35141814, step = 4400 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.413\n",
      "INFO:tensorflow:loss = 0.3373801, step = 4500 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.644\n",
      "INFO:tensorflow:loss = 0.3264992, step = 4600 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.054\n",
      "INFO:tensorflow:loss = 0.32190734, step = 4700 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.039\n",
      "INFO:tensorflow:loss = 0.3261987, step = 4800 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.137\n",
      "INFO:tensorflow:loss = 0.33260673, step = 4900 (0.229 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/04/l_r6_2qd69907ztc_b_d2qz00000gn/T/tmp7gmac15_/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.3183505.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1120d4710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model \n",
    "classifier.train(\n",
    "    input_fn = lambda : input_fn(train_df, train_y, training=True),\n",
    "    steps = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breaking down what we did above:\n",
    "\n",
    "Let's start with the **input function**. So here, we didn't have to make a function within a function as in Regression when we want to use the input function to train our model we create something called **lambda**.\n",
    "\n",
    "##### what is lambda?\n",
    "Lambda is an anomymous function that can be defined in one line. So when we write lambda what that means is that this is a function that will execute whatever comes after it. Thus, here we have a chain of functions (lambda and input_fn), we essentially ask lambda to call the ```input_fn()``` that we created earlier. The reason we are using lambda here is because we didn't create an exterior input_fn to return us the internal input_fn as we did in Regression. \n",
    "\n",
    "For more info about the **lambda function** check this [link](https://www.programiz.com/python-programming/anonymous-function). \n",
    "\n",
    "Now the ```input_fn()``` needs a few parameters/arguments. It needs features(train_df), label(y values), and we also need to specify that this tarining and not evaluation, and a number of steps.\n",
    "**Steps** are similar to epochs.\n",
    "\n",
    "#### output of training\n",
    "\n",
    "what is the loss that we get in the output? Let's say for now that the smallest the loss the better!\n",
    "\n",
    "### Evaluate the model\n",
    "\n",
    "Now that the model has been trained let's get some statistics and look at the performance. The code below evaluates the accuracy of the trained model on the test data. For evaluation we can use the ```.evaluate``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-21T15:35:07Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/04/l_r6_2qd69907ztc_b_d2qz00000gn/T/tmp7gmac15_/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.44761s\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-21-15:35:08\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.93333334, average_loss = 0.37486255, global_step = 5000, loss = 0.37486255\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/04/l_r6_2qd69907ztc_b_d2qz00000gn/T/tmp7gmac15_/model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_results = classifier.evaluate(\n",
    "    input_fn = lambda: input_fn(test_df, test_y, training = False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got an accuracy of 97% which is really good, but let's not forget the test dataset is very small (30 values) and this will change a bit every time we train the model. \n",
    "\n",
    "### Make predictions using the trained model\n",
    "\n",
    "So we have trained a model that generates good evaluation results. Let's make predictions.\n",
    "Here we have a small, silly game in which the model predicts the class of a flower based on usre's input:\n",
    "\n",
    "This code below is a combination of the TensorFlow 2.0. course provided by FreeCodeCamp and the TensorFlow documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make an input function for features \n",
    "def input_fn(features, batch_size=256):\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "# define the features\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type numeric values as prompted.\") # only one value each time\n",
    "for feature in features:\n",
    "    valid = True\n",
    "    while valid:\n",
    "        val = input(feature + \": \")\n",
    "        if not val.isdigit(): valid = False\n",
    "            \n",
    "    predict[feature] = [float(val)]\n",
    "    \n",
    "    # call the input function\n",
    "    predictions = classifier.predict(input_fn= lambda: input_fn(predict))\n",
    "\n",
    "for pred_dict in predictions:\n",
    "    \n",
    "    print(pred_dict)\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "    \n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES_COLUMN_NAMES[class_id], 100 * probability))\n",
    "    \n",
    "    \n",
    "# here is some example input (x values) and expected classes that we can try:\n",
    "'''\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we did above.\n",
    "\n",
    "First we created an input function, only this one needs the features and not features and labels. The reason we don't pass the labels (y values) is because we'll use it for prediction, thus we want the model to give us the answer. \n",
    "\n",
    "In the **for** loop etc... we wait for some valid response (**while** valid etc..) and once we get the response we add it to the **predict** dictionary.\n",
    "\n",
    "Now, what we get when we call the input function is a dictionary. So then we loop through that dictionary to get some specific information.\n",
    "Let's see what the pred_dict **for** loop does in more detail:\n",
    "\n",
    "So *pred_dict* is also a dictionary and we are interested in class_ids and the probabilities (in this dictionary).\n",
    "**class_id** is an array and it contains one of three values (either 0,1 or 2) depending on the prediction that the model has made (in other words: *what flower did the model predict based on the values that we passed?*)\n",
    "\n",
    "The **probabilities** key has three values (because we have 3 classes), so each of these values is the probabilty for each of the classes ('Setosa', 'Versicolor', 'Virginica') based on the input that we gave. Now, we don't print all three probabilities but only the probability of the class_id that the model estimated to be the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
